{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -U -q langchain_mistralai, langgraph"
      ],
      "metadata": {
        "id": "WwxD6U1dWsmU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "xD8atrfNS6e5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = getpass.getpass(\"Enter your Mistral API key: \")\n",
        "os.environ[\"MISTRAL_API_KEY\"] = API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_loVd0ad8Ii",
        "outputId": "f655c819-6a95-4aa0-f81b-55c4e5ab9305"
      },
      "execution_count": 60,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatMistralAI(model=\"mistral-small-latest\")\n"
      ],
      "metadata": {
        "id": "i8xu1tkRXbJ0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"Hello! Are you working?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfWwtnedXqfl",
        "outputId": "6b877d62-4cf0-40c9-a6d4-cf49c9eb6362"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! Yes, I'm here and ready to assist you. What do you need help with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage"
      ],
      "metadata": {
        "id": "ZbTzaQ98cZQ5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "\n",
        "    text: str  # Stores the original input text\n",
        "    classification: str  # Represents the classification result (e.g., category label)\n",
        "    entities: List[str]  # Holds a list of extracted entities (e.g., named entities)\n",
        "    summary: str  # Stores a summarized version of the text"
      ],
      "metadata": {
        "id": "kf4mJS7ZcsbJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_node(state: State):\n",
        "   \"\"\"\n",
        "   Classify the text into one of predefined categories.\n",
        "\n",
        "   Parameters:\n",
        "       state (State): The current state dictionary containing the text to classify\n",
        "\n",
        "   Returns:\n",
        "       dict: A dictionary with the \"classification\" key containing the category result\n",
        "\n",
        "   Categories:\n",
        "       - News: Factual reporting of current events\n",
        "       - Blog: Personal or informal web writing\n",
        "       - Research: Academic or scientific content\n",
        "       - Other: Content that doesn't fit the above categories\n",
        "   \"\"\"\n",
        "\n",
        "   # Define a prompt template that asks the model to classify the given text\n",
        "   prompt = PromptTemplate(\n",
        "       input_variables=[\"text\"],\n",
        "       template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText: {text}\\n\\nCategory:\"\n",
        "   )\n",
        "\n",
        "   # Format the prompt with the input text from the state\n",
        "   message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "\n",
        "   # Invoke the language model to classify the text based on the prompt\n",
        "   classification = llm.invoke([message]).content.strip()\n",
        "\n",
        "   # Return the classification result in a dictionary\n",
        "   return {\"classification\": classification}"
      ],
      "metadata": {
        "id": "NUixBfO-cwzq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_extraction_node(state: State):\n",
        "  # Function to identify and extract named entities from text\n",
        "  # Organized by category (Person, Organization, Location)\n",
        "\n",
        "  # Create template for entity extraction prompt\n",
        "  # Specifies what entities to look for and format (comma-separated)\n",
        "  prompt = PromptTemplate(\n",
        "      input_variables=[\"text\"],\n",
        "      template=\"Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\\n\\nText: {text}\\n\\nEntities:\"\n",
        "  )\n",
        "\n",
        "  # Format the prompt with text from state and wrap in HumanMessage\n",
        "  message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "\n",
        "  # Send to language model, get response, clean whitespace, split into list\n",
        "  entities = llm.invoke([message]).content.strip().split(\", \")\n",
        "\n",
        "  # Return dictionary with entities list to be merged into agent state\n",
        "  return {\"entities\": entities}"
      ],
      "metadata": {
        "id": "SeGEiKvzc5cX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_node(state: State):\n",
        "    # Create a template for the summarization prompt\n",
        "    # This tells the model to summarize the input text in one sentence\n",
        "    summarization_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Summarize the following text in one short sentence.\n",
        "\n",
        "        Text: {text}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "    )\n",
        "\n",
        "    # Create a chain by connecting the prompt template to the language model\n",
        "    # The \"|\" operator pipes the output of the prompt into the model\n",
        "    chain = summarization_prompt | llm\n",
        "\n",
        "    # Execute the chain with the input text from the state dictionary\n",
        "    # This passes the text to be summarized to the model\n",
        "    response = chain.invoke({\"text\": state[\"text\"]})\n",
        "\n",
        "    # Return a dictionary with the summary extracted from the model's response\n",
        "    # This will be merged into the agent's state\n",
        "    return {\"summary\": response.content}"
      ],
      "metadata": {
        "id": "ff3v2BoVc6E9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification_node\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarize_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification_node\") # Set the entry point of the graph\n",
        "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "8NUGcAlZc8tn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sample text about Anthropic's MCP to test our agent\n",
        "sample_text = \"\"\"\n",
        "Anthropic's MCP (Model Context Protocol) is an open-source powerhouse that lets your applications interact effortlessly with APIs across various systems.\n",
        "\"\"\"\n",
        "\n",
        "# Create the initial state with our sample text\n",
        "state_input = {\"text\": sample_text}\n",
        "\n",
        "# Run the agent's full workflow on our sample text\n",
        "result = app.invoke(state_input)"
      ],
      "metadata": {
        "id": "Ui9_gikhdARp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print each component of the result:\n",
        "# - The classification category (News, Blog, Research, or Other) ### -> Expected Response: Technology\n",
        "print(\"Classification:\", result[\"classification\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OZZV9wQdH37",
        "outputId": "68ce68e2-7052-4dd5-df8d-89f4f8e456bf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification: The text provided appears to be promotional or descriptive in nature, likely aimed at informing readers about a specific technology or product. It does not fit the characteristics of News (which typically reports on current events), Blog (which usually includes personal opinions or detailed discussions), or Research (which involves in-depth analysis and findings). Therefore, the most appropriate category for this text is:\n",
            "\n",
            "**Other**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - The extracted entities (People, Organizations, Locations) ### -> Expected Response [‘Anthropic’, ‘MCP’, ‘Model Context Protocol’]\n",
        "print(\"\\nEntities:\", result[\"entities\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF7bq9lsdPiH",
        "outputId": "aface2cd-9a64-4c92-e898-c82312238c1d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entities: ['The provided text does not contain any entities that fall into the categories of Person', 'Organization', 'or Location. Therefore', 'the result is:\\n\\nEntities:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# - The generated summary of the text\n",
        "print(\"\\nSummary:\", result[\"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3N_jjHRdUgv",
        "outputId": "64ea85cf-8863-4ed1-8804-620dae3f4003"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary: Anthropic's MCP is an open-source tool for seamless API interactions across different systems.\n"
          ]
        }
      ]
    }
  ]
}